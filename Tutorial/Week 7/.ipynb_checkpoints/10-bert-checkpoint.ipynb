{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wLWYdE939yj"
   },
   "source": [
    "# Fine-tuning with BERT\n",
    "\n",
    "In this workshop, we'll learn how to use a pre-trained BERT model for a sentiment analysis task. We'll be using the [pytorch](https://pytorch.org/) framework, and [huggingface's transformers library](https://github.com/huggingface/transformers), which provides a suite of transformer models with a consistent interface.\n",
    "\n",
    "Note: You may find certain parts of the code difficult to follow. This is because the model is designed based on the pytorch framework, so there'll be  pytorch syntax littered throughout the code. If you want to understand the code better, you're encouraged to do the [pytorch tutorial](https://pytorch.org/tutorials/), and also going through [the code of a pytorch language model](https://github.com/pytorch/examples/tree/master/word_language_model).\n",
    "\n",
    "Now let's enable GPU on the colab notebook. We can do this by going to \"Runtime $>$ Change runtime type\" and selecting \"GPU\" as the hardware accelerator. Click save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzCW5f2vnE9b"
   },
   "source": [
    "First let's install the pytorch and transformers packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3355,
     "status": "ok",
     "timestamp": 1618296949890,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "zkioaw3DnE9c",
    "outputId": "f0a3fbf6-3163-4dc0-8411-0d50bbd0d752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: torchvision in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: transformers in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: requests in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: filelock in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: packaging in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: six in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: click in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/rongxinz1/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/rongxinz1/opt/anaconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0LPPNAInE9i"
   },
   "source": [
    "The installation will take a couple minutes.\n",
    "\n",
    "Once the packages are installed, we'll load a pre-trained BERT model. We'll use the smaller uncased BERT model (uncased means the data used for pre-training BERT is all lowercased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132,
     "referenced_widgets": [
      "a558fc732c0c4c4b8a12605616d16ad4",
      "cde329ab4a2f4e309625b83d983eb665",
      "9fc0faf7ddd0476c9f32d4cf8ef342f2",
      "7b93a28e1141420dbda5776e4bb2ea25",
      "e123376683094b41a8e151deb142792e",
      "4ad237b0e16c4243b7b0b2fb8a428cbd",
      "7d5abd77586d4b6d91c4088f32d10ce9",
      "498525097ea14544ac558920c387bf7f",
      "b7536f77337c48b3ad5486076262d167",
      "52651e00187e4df087181b6fc25e05c1",
      "9ab077c6d9f34e00aa2901e5903d7580",
      "51d92c91a2a24616b389d9aff1e021b2",
      "2aba1e75e26b4835b0c165c46b1185c6",
      "37a1805a791b43bc9ba1d73948637d65",
      "e8e0159d124c49d28770433457f526d1",
      "2c33295e9e194beea8288f61084965db"
     ]
    },
    "executionInfo": {
     "elapsed": 18266,
     "status": "ok",
     "timestamp": 1618296964815,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "sgde1MeD39yk",
    "outputId": "4f92ffe6-9f79-4290-9824-f840e3c48f3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading BERT model.\n"
     ]
    }
   ],
   "source": [
    "#load pretrained bert base model\n",
    "from transformers import BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"Done loading BERT model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59ifoyqGA-7m"
   },
   "source": [
    "BERT uses WordPiece tokenisation, which is a sub-word tokenisation algorithm like BPE. Let's tokenise a sentence with WordPiece and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181,
     "referenced_widgets": [
      "b75137e6267f46668a8e96dbd40b97f8",
      "7322fae0d93e420c87b04b9fe76592fe",
      "b50cb156207047cd8f441ea8470f9c21",
      "d4732e5208b64242a6dd69ece05aff11",
      "6c4d3eaaae4048b4a049e04b52c9ce2a",
      "8ddafd877934427ca608eb50d277c6cc",
      "6c72db6eda8349d9854cce41c22751eb",
      "e2b65a56abce4c1bb4fa4839e128ccfc",
      "3b4c267b7ad84748841b1d9a6af6d93b",
      "fb34b640799c41d89788a07190d53c36",
      "4125d0410f38414e81dad276d1e882ad",
      "fb57e22ba2ee44baae2bb834d56b93e8",
      "9e9552fe12084124866f393272f0ff6a",
      "53a23b0c63874ad0a02533ef7a536600",
      "bd64e784923b40139c25b863d572a14b",
      "cf92febcf4724c5fa98205d103dcf918",
      "b252d105ce094f67ad6018babf79e503",
      "e3720bead30647298a5385313f3c1f13",
      "5d9636dd20f047a797ab17f6de8f9092",
      "56b8940646da472983892ec6d3c6aa98",
      "c47214219e3949448867964eb041ea0a",
      "1c9ab2648f5a46e2a7d597b1864bfd73",
      "932670e9e28b48a28dfbceb141db7c19",
      "6681c34c26174cd8b2e814ed4e15f87b"
     ]
    },
    "executionInfo": {
     "elapsed": 20893,
     "status": "ok",
     "timestamp": 1618296967453,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "2EqbuS_f39yu",
    "outputId": "635647f4-87a1-4c5e-96c8-18e0ce8ea058"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcc1690bc94487d9386e602b4d06bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03ba56953ed4506b77f5b0b6efd714f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'enjoyed', 'this', 'movie', 'soo', '##oo', '##o', 'much', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#load BERT's WordPiece tokenisation model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentence = 'I enjoyed this movie sooooo much.'\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6IDDDbznE9p"
   },
   "source": [
    "We can see for most words, they are tokenised as single words. But for the word \"sooooo\" it's tokenised into three subwords: \"soo\", \"##oo\" and \"##o\". The double hashtag \"##\" is a symbol to indicate a subword span of within a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTrn2FVu39yw"
   },
   "source": [
    "BERT prepends every sentence with a special [CLS] token. As we saw in the lecture, we need this token when we fine-tune BERT for downstream tasks (e.g. spam detection).\n",
    "\n",
    "BERT also terminates a sentence with a special [SEP] token. While this token doesn't do much when we're working with problems that have single sentences as input (e.g. sentiment classification), it's useful when we're working with problems that involve sentence pairs (e.g. textual entailment and sentence similarity classification). In those cases, we need [SEP] to indicate when the first sentence finishes, and when the second sentence starts (e.g. for the sentence pair (_this movie is fantastic_, _this film is amazing_), the input to BERT will be: `[CLS] this movie is fantastic [SEP] this film is amazing [SEP]`).\n",
    "\n",
    "Note: Recall that in addition to the masked language model objective, BERT is also pre-trained with the next-sentence prediction objective. [SEP] is needed for the next-sentence objective (since it involves a sentence pair), and [CLS] is also used in this objective to classify the input sentence pair. And so [CLS] and [SEP] isn't used only during fine-tuning; they are also used during pre-training.\n",
    "\n",
    "Now let's preprocess the sentence by prepending [CLS] and appending [SEP]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20885,
     "status": "ok",
     "timestamp": 1618296967454,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "ZTAmBw3D39yx",
    "outputId": "26c0fc9d-ff10-42b8-f6ef-a4005a15e2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'enjoyed', 'this', 'movie', 'soo', '##oo', '##o', 'much', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YMusTTk39y0"
   },
   "source": [
    "Since we'll be using minibatches when fine-tuning BERT, we need to pad the input sequences so that they are all of the same length. We'll use the [PAD] token for this.\n",
    "\n",
    "Additionally, we need to create an attention mask vector. This attention mask vector is a binary vector and it tells BERT what words should and should not be attended. We need the attention mask vector here because we want BERT to ignore the [PAD] tokens (i.e. to not consider them when doing self-attention).\n",
    "\n",
    "Now let's pad the input sequence to a fixed length (12 in this example) and create the binary attention mask vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20879,
     "status": "ok",
     "timestamp": 1618296967455,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "YzSB6zff39y0",
    "outputId": "9b65d034-f7a6-41a7-ccf5-ae2b6bf62e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'enjoyed', 'this', 'movie', 'soo', '##oo', '##o', 'much', '.', '[SEP]', '[PAD]']\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "T = 12\n",
    "\n",
    "padded_tokens = tokens + ['[PAD]' for _ in range(T - len(tokens))]\n",
    "print(padded_tokens)\n",
    "\n",
    "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "print(attn_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xsoI8Hz39y3"
   },
   "source": [
    "The last preprocessing step is to create the segment IDs. The segment IDs is again a binary vector, and denotes the sentence IDs (first or second sentence) in the input sequence. We use 0 to denote the first sentence, and 1 the second sentence. As we are working with a single sentence as input for sentiment analysis, the segment IDs is just a vector of 0's. But for a sentence pair classification problem like sentence similarity classification, an input like `[CLS] this movie is fantastic [SEP] this film is amazing [SEP]` would have a segment IDs of `[0 0 0 0 0 0 1 1 1 1 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20873,
     "status": "ok",
     "timestamp": 1618296967455,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "pwdVZux_39y3",
    "outputId": "83ab3d85-2a0b-4649-d716-d6cf0221e105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "seg_ids = [0 for _ in range(len(padded_tokens))] #Since we only have a single sequence as input\n",
    "print(seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-d4Fdn039y7"
   },
   "source": [
    "Now let's convert the tokens in preprocessed sentence into their respective vocab IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20867,
     "status": "ok",
     "timestamp": 1618296967456,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "Gc79UDdt39y7",
    "outputId": "e22182b2-2aa9-4a6b-ec18-5ddcb89e51f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1045, 5632, 2023, 3185, 17111, 9541, 2080, 2172, 1012, 102, 0]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2gyfDLB39y-"
   },
   "source": [
    "We can see [CLS] has a vocab ID of 101, [SEP] 102 and [PAD] 0.\n",
    "\n",
    "Next let's turn the IDs into torch tensors, and feed the input sequence to BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21401,
     "status": "ok",
     "timestamp": 1618296967996,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "jrQWFNd139y-",
    "outputId": "c030d20e-6fd0-4dd4-bd7d-b26f5510ac4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 768])\n",
      "tensor([ 0.2897, -0.3014,  0.1959, -0.1320, -0.3270, -0.8532,  0.0598,  0.6822,\n",
      "         0.2358, -0.0022], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#Converting all the input vectors to torch tensors\n",
    "token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "\n",
    "#Feed them to bert and get the contextualised embeddings\n",
    "outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "hidden_reps = outputs.last_hidden_state\n",
    "print(hidden_reps.shape)\n",
    "print(hidden_reps[0, 0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2897, -0.3014,  0.1959,  ..., -0.0958,  0.3376,  0.1563],\n",
       "         [ 0.5463, -0.1040, -0.2302,  ..., -0.5539,  1.3040,  0.0909],\n",
       "         [ 0.2217, -0.2371,  0.4979,  ...,  0.2492,  0.6089,  0.1247],\n",
       "         ...,\n",
       "         [ 0.4422, -0.0403, -0.0268,  ..., -0.0420, -0.2224, -0.4036],\n",
       "         [ 0.2779,  0.0774,  0.1720,  ...,  0.0678, -0.3991, -0.2619],\n",
       "         [ 0.3242,  0.1621,  0.2263,  ..., -0.0401,  0.0655,  0.2258]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8147, -0.2866, -0.2828,  0.3553,  0.4304, -0.1323,  0.5513,  0.1460,\n",
       "         -0.4065, -0.9997,  0.0488,  0.7719,  0.9695, -0.3060,  0.8111, -0.2278,\n",
       "         -0.0831, -0.3446,  0.1335, -0.1858,  0.3774,  0.9967,  0.5300,  0.1327,\n",
       "          0.2230,  0.8797, -0.5679,  0.8530,  0.9207,  0.6267, -0.3032,  0.1041,\n",
       "         -0.9829,  0.0079, -0.1090, -0.9731,  0.1556, -0.6543,  0.2204,  0.1245,\n",
       "         -0.8616,  0.1368,  0.9990, -0.7155, -0.1709, -0.1238, -0.9999,  0.0770,\n",
       "         -0.7845,  0.3781,  0.1399,  0.5695,  0.0205,  0.2722,  0.3560,  0.2098,\n",
       "         -0.2658, -0.0595, -0.0440, -0.4756, -0.5247,  0.0545, -0.4219, -0.8215,\n",
       "          0.5769,  0.0356,  0.1360, -0.1097,  0.0253, -0.1156,  0.7797,  0.0365,\n",
       "          0.2279, -0.7248, -0.1170,  0.1638, -0.3849,  1.0000,  0.0323, -0.9620,\n",
       "          0.5160,  0.1001,  0.2805,  0.4219, -0.4368, -1.0000,  0.3168,  0.1062,\n",
       "         -0.9829,  0.0019,  0.3854, -0.2207, -0.0739,  0.3148,  0.0362,  0.0420,\n",
       "         -0.0059, -0.3518,  0.0444, -0.0400, -0.1537,  0.0030,  0.0042, -0.1680,\n",
       "          0.1385, -0.3239, -0.1890,  0.3655, -0.2368,  0.4520,  0.2040, -0.1433,\n",
       "          0.1269, -0.9287,  0.4091, -0.0762, -0.9822, -0.3798, -0.9842,  0.4422,\n",
       "          0.1775, -0.0106,  0.8992,  0.3311,  0.1694,  0.2367, -0.5327, -1.0000,\n",
       "         -0.1906,  0.1122,  0.0237, -0.1104, -0.9666, -0.9502,  0.4643,  0.9362,\n",
       "          0.0702,  0.9978,  0.0020,  0.8959,  0.2064, -0.2533,  0.1889, -0.2382,\n",
       "          0.1840, -0.3376, -0.0819,  0.0026,  0.1006, -0.0706, -0.3137,  0.0513,\n",
       "         -0.0803, -0.8796, -0.2689,  0.8928, -0.0815, -0.3158,  0.4376,  0.0207,\n",
       "          0.0315,  0.6476,  0.2090,  0.1327, -0.0264,  0.2907, -0.6288,  0.2333,\n",
       "         -0.6219,  0.2822,  0.2779, -0.1752, -0.1075, -0.9683, -0.1706,  0.3623,\n",
       "          0.9739,  0.6277,  0.0154,  0.3049, -0.0508,  0.4010, -0.9296,  0.9717,\n",
       "         -0.1154,  0.0876,  0.1544,  0.4131, -0.7722, -0.5401,  0.4947, -0.4293,\n",
       "         -0.8283,  0.1966, -0.3401, -0.2282, -0.3685,  0.3756, -0.1141, -0.1195,\n",
       "          0.0769,  0.8602,  0.8551,  0.6063, -0.3004,  0.2626, -0.8473, -0.1532,\n",
       "         -0.0584, -0.0448,  0.1088,  0.9897,  0.0693,  0.0445, -0.9029, -0.9770,\n",
       "         -0.1744, -0.8363,  0.0114, -0.4579,  0.2583,  0.0366, -0.1069,  0.1139,\n",
       "         -0.9101, -0.5585,  0.0678, -0.2402,  0.2180, -0.1085,  0.8436,  0.5758,\n",
       "         -0.3090,  0.1101,  0.8713, -0.6476, -0.6008,  0.3821, -0.1090,  0.7909,\n",
       "         -0.3221,  0.9458,  0.4858,  0.6199, -0.8359, -0.2613, -0.7675,  0.0349,\n",
       "         -0.0296, -0.7091,  0.3359,  0.3349,  0.3010,  0.8721, -0.2911,  0.9668,\n",
       "         -0.9338, -0.9262, -0.5011,  0.1798, -0.9802,  0.3343,  0.1893, -0.2557,\n",
       "         -0.2253, -0.1797, -0.9398,  0.5697, -0.0527,  0.9153,  0.0651, -0.5921,\n",
       "         -0.3918, -0.8743, -0.4059, -0.0824,  0.1960, -0.2405, -0.9079,  0.3191,\n",
       "          0.3430,  0.2509, -0.0893,  0.9870,  0.9999,  0.9586,  0.7420,  0.7777,\n",
       "         -0.9847, -0.7861,  0.9998, -0.9180, -1.0000, -0.8803, -0.3327,  0.0712,\n",
       "         -1.0000, -0.0932,  0.2549, -0.8878, -0.1244,  0.9669,  0.9279, -1.0000,\n",
       "          0.7531,  0.9008, -0.2559,  0.7780, -0.0239,  0.9525,  0.3708,  0.3515,\n",
       "         -0.0302,  0.1939, -0.4881, -0.5496,  0.0730, -0.3204,  0.9492, -0.0764,\n",
       "         -0.4652, -0.8227,  0.0223, -0.0080, -0.5012, -0.9452,  0.0244,  0.0748,\n",
       "          0.5696,  0.0903,  0.0890, -0.4628,  0.0521, -0.5681, -0.2466,  0.3966,\n",
       "         -0.8957, -0.3104,  0.2084, -0.3569,  0.1652, -0.9374,  0.9244, -0.3841,\n",
       "          0.2868,  1.0000,  0.0778, -0.6826,  0.1940,  0.0204,  0.0974,  1.0000,\n",
       "          0.5785, -0.9627, -0.3103,  0.1814, -0.4114, -0.2800,  0.9923, -0.2047,\n",
       "         -0.0577,  0.1286,  0.9644, -0.9813,  0.8922, -0.7795, -0.9506,  0.9530,\n",
       "          0.9067, -0.3166, -0.6229,  0.0185,  0.3453,  0.1376, -0.9089,  0.5567,\n",
       "          0.0446,  0.0058,  0.8100, -0.4410, -0.3458,  0.1265, -0.2953,  0.1433,\n",
       "          0.5390,  0.2746,  0.0700, -0.0233,  0.0255, -0.6317, -0.9702,  0.1102,\n",
       "          1.0000, -0.0704,  0.1029, -0.0052,  0.0620, -0.3388,  0.3565,  0.3173,\n",
       "         -0.2195, -0.7020,  0.4333, -0.8344, -0.9768,  0.4764,  0.1200,  0.0035,\n",
       "          0.9983,  0.0442, -0.0122,  0.2311,  0.8713, -0.2680,  0.2168,  0.2138,\n",
       "          0.9628,  0.0143,  0.2748,  0.7386, -0.2619,  0.0398, -0.4871, -0.0859,\n",
       "         -0.8858,  0.2184, -0.9406,  0.9266,  0.5373,  0.1221, -0.0416,  0.0632,\n",
       "          1.0000, -0.5278,  0.2257,  0.2738,  0.2283, -0.9931, -0.4959, -0.2356,\n",
       "          0.1225, -0.2057, -0.0717,  0.1397, -0.9523, -0.0036,  0.2504, -0.8616,\n",
       "         -0.9710, -0.0258,  0.5640, -0.1108, -0.7921, -0.3233, -0.4612,  0.2608,\n",
       "         -0.0172, -0.9025,  0.4841, -0.0680,  0.3485, -0.0520,  0.2956, -0.0013,\n",
       "          0.9408, -0.0899,  0.0732,  0.1364, -0.6219,  0.4635, -0.5493, -0.3235,\n",
       "          0.0144,  1.0000, -0.4510,  0.3933,  0.5360,  0.5815,  0.0445, -0.0279,\n",
       "          0.5104,  0.1530,  0.1609, -0.2415,  0.1692, -0.0248,  0.3213, -0.0800,\n",
       "         -0.2795,  0.6662,  0.6619,  0.1327,  0.0579, -0.1786,  0.9908,  0.0423,\n",
       "          0.0041, -0.3180,  0.2359, -0.2747,  0.4874,  1.0000,  0.1854, -0.2290,\n",
       "         -0.9801, -0.2924, -0.6397,  0.9998,  0.8273, -0.7258,  0.5217,  0.3857,\n",
       "          0.0240,  0.3764, -0.0063, -0.0678,  0.1228, -0.1297,  0.9210, -0.3813,\n",
       "         -0.9635, -0.3613,  0.1956, -0.9352,  0.9907, -0.3993, -0.0935, -0.3391,\n",
       "          0.1886, -0.4462, -0.1582, -0.9765,  0.0495, -0.0595,  0.9373, -0.0595,\n",
       "         -0.2841, -0.7878,  0.2871,  0.3241, -0.5069, -0.8972,  0.9341, -0.9507,\n",
       "          0.4683,  1.0000,  0.1851, -0.4356, -0.0668, -0.2376,  0.1972, -0.0032,\n",
       "          0.2786, -0.9380, -0.2077,  0.0373,  0.2216,  0.0374, -0.1527,  0.4234,\n",
       "          0.0615, -0.1991, -0.4844,  0.1527,  0.2370,  0.5443, -0.0497, -0.0042,\n",
       "         -0.0575,  0.0490, -0.6820, -0.2338, -0.2425, -0.9981,  0.4160, -1.0000,\n",
       "         -0.0377, -0.6003, -0.1103,  0.7287,  0.8219,  0.2820, -0.4430, -0.3164,\n",
       "          0.8005,  0.5951, -0.0626,  0.0815, -0.4884,  0.0643,  0.1272,  0.1320,\n",
       "          0.1391,  0.6242, -0.1780,  1.0000, -0.0299, -0.1273, -0.9080,  0.0904,\n",
       "         -0.0168,  1.0000, -0.7484, -0.9364, -0.0431, -0.4060, -0.6656,  0.1714,\n",
       "         -0.0907, -0.5105, -0.6952,  0.7966,  0.4792, -0.4130,  0.1981, -0.0790,\n",
       "         -0.3324, -0.2250,  0.2506,  0.9819,  0.1292,  0.7270, -0.2795, -0.0633,\n",
       "          0.9371,  0.0652, -0.1703, -0.1133,  1.0000,  0.1079, -0.8260,  0.3218,\n",
       "         -0.9625,  0.0489, -0.9242,  0.1706, -0.0646,  0.8813, -0.1922,  0.8675,\n",
       "         -0.0951, -0.0915, -0.1535,  0.3283,  0.1409, -0.8360, -0.9656, -0.9730,\n",
       "          0.4018, -0.2254,  0.0597,  0.1104, -0.0952,  0.2033,  0.2827, -1.0000,\n",
       "          0.8894,  0.1451,  0.0983,  0.9421,  0.4561,  0.2619,  0.1048, -0.9665,\n",
       "         -0.9026, -0.1629, -0.1529,  0.3296,  0.4307,  0.7655,  0.2081, -0.3923,\n",
       "         -0.3848,  0.1042, -0.9416, -0.9885,  0.1525,  0.0960, -0.8093,  0.8964,\n",
       "         -0.6089,  0.0898,  0.4052, -0.4951,  0.7889,  0.6099,  0.0515, -0.0856,\n",
       "          0.4311,  0.7961,  0.7843,  0.9546, -0.2816,  0.4094, -0.2417,  0.2315,\n",
       "          0.8114, -0.9188, -0.0351, -0.0862,  0.3085,  0.0548,  0.0242, -0.8852,\n",
       "          0.0845, -0.1081,  0.2236, -0.2002,  0.1787, -0.2304, -0.0463, -0.5552,\n",
       "         -0.5300,  0.4731, -0.1027,  0.8070,  0.5956,  0.0381, -0.2259, -0.1342,\n",
       "          0.0580, -0.8855,  0.6482,  0.2347,  0.5747, -0.1233, -0.2529,  0.7598,\n",
       "         -0.3905, -0.2869, -0.2209, -0.5127,  0.7416, -0.4266, -0.2494, -0.2896,\n",
       "          0.5279,  0.1222,  0.9937,  0.0132, -0.5210, -0.3617, -0.2661,  0.1434,\n",
       "         -0.0098, -1.0000,  0.0979, -0.4036,  0.1119, -0.3179,  0.4669, -0.2150,\n",
       "         -0.9109,  0.1169,  0.4283,  0.3024, -0.4315, -0.4316,  0.2813,  0.1406,\n",
       "          0.8258,  0.7697,  0.5705,  0.5824,  0.3815, -0.3345, -0.4833,  0.8458]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6v5VMTm39zB"
   },
   "source": [
    "`hidden_reps` is the contextualised embeddings for all tokens in the sentence\n",
    "\n",
    "It has a dimension of [1, 12, 768] because we have one sentence in our minibatch, and that sentence has a length of 12 tokens, and each token has a contextualised embedding of 768 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_NGjrIk39zB"
   },
   "source": [
    "Now that we understood how to preprocess sentences and get the contextualised embeddings from BERT, let's move to the actual classification problem: sentiment analysis.\n",
    "\n",
    "We'll be using the Stanford sentiment treebank data as our dataset. Let's upload the data (10-train.tsv and 10-dev.tsv) to colab. We can do this by clicking the folder icon on the left, and selecting \"Upload\" to upload the two files.\n",
    "\n",
    "Once the files are uploaded, you should see them appearing in the file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIbjzUAInE97"
   },
   "source": [
    "We'll now create `SSTDataset`, a dataset class to load the data, and provide a function `__getitem__` to fetch a sentence, preprocess it (following the steps we did earlier) and return the tokenised sentence, attention mask and ground truth label.\n",
    "\n",
    "Note: we do not need to create the segment IDs here since we're working with a task (sentiment analysys) that only has single sentences as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21400,
     "status": "ok",
     "timestamp": 1618296967997,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "DGtUWjhr39zC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class SSTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename, maxlen):\n",
    "\n",
    "        #Store the contents of the file in a pandas dataframe\n",
    "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
    "\n",
    "        #Initialize the BERT tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        sentence = self.df.loc[index, 'sentence']\n",
    "        label = self.df.loc[index, 'label']\n",
    "\n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrc6aHBW39zE"
   },
   "source": [
    "Now let's create the training and development data using the `SSTDataset` class and pytorch's `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23686,
     "status": "ok",
     "timestamp": 1618296970290,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "pzhUQHT439zF",
    "outputId": "d82f0d68-0546-4a62-9128-f50a0dbc944e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preprocessing training and development data.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Creating instances of training and development set\n",
    "#maxlen sets the maximum length a sentence can have\n",
    "#any sentence longer than this length is truncated to the maxlen size\n",
    "train_set = SSTDataset(filename = '10-train.tsv', maxlen = 30)\n",
    "dev_set = SSTDataset(filename = '10-dev.tsv', maxlen = 30)\n",
    "\n",
    "#Creating intsances of training and development dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = 64, num_workers = 2)\n",
    "dev_loader = DataLoader(dev_set, batch_size = 64, num_workers = 2)\n",
    "\n",
    "print(\"Done preprocessing training and development data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2t1KRAE39zH"
   },
   "source": [
    "Recall how we use BERT for downstream task:\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/bert-classifier.png\" width=\"70%\">\n",
    "\n",
    "We feed the input sequence to BERT, and take the contextualised embedding of [CLS] produced by BERT, and pass it to a classifier, which can be a simple feedforward network. As our task is a binary classification problem (positive or negative sentiment label), we only need the output layer to produce a single scalar value to denote the probability of the positive class.\n",
    "\n",
    "Note: when we fine-tune our model we'll update all the parameters in the model (BERT's and the classification layer's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23686,
     "status": "ok",
     "timestamp": 1618296970291,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "-mC5rpX939zI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Classification layer\n",
    "        #input dimension is 768 because [CLS] embedding has a dimension of 768\n",
    "        #output dimension is 1 because we're working with a binary classification problem\n",
    "        self.cls_layer = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbapDA4HnE-F"
   },
   "source": [
    "Now let's create the sentiment classifier with pre-trained BERT's parameters. We'll put the model on GPU. This step might take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37403,
     "status": "ok",
     "timestamp": 1618296984019,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "uuT4iQWN39zK",
    "outputId": "1f2afde6-bb6e-4005-e66f-f84b325d8851"
   },
   "outputs": [],
   "source": [
    "gpu = 0 #gpu ID\n",
    "\n",
    "print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n",
    "net = SentimentClassifier()\n",
    "net.cuda(gpu) #Enable gpu support for the model\n",
    "print(\"Done creating the sentiment classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaKjG-RL39zN"
   },
   "source": [
    "We need to define a loss function for our model. Since it's a binary task, we'll use binary cross-entropy. We'll also use Adam as our optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37402,
     "status": "ok",
     "timestamp": 1618296984020,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "uEFvInHa39zN"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bczJ88nc39zP"
   },
   "source": [
    "Next let's define the training function. During training, we fetch a minibatch of examples from the data loader, and feed it to the classifier to get the output logits and compute the loss. `loss.backward()` is a function to compute the gradients for the parameters based on the loss, and `opti.step()` is a function to update parameters using the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37400,
     "status": "ok",
     "timestamp": 1618296984020,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "NZlOKYq339zP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n",
    "\n",
    "    best_acc = 0\n",
    "    st = time.time()\n",
    "    for ep in range(max_eps):\n",
    "        \n",
    "        net.train()\n",
    "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            #Clear gradients\n",
    "            opti.zero_grad()  \n",
    "            #Converting these to cuda tensors\n",
    "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
    "\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, attn_masks)\n",
    "\n",
    "            #Computing loss\n",
    "            loss = criterion(logits.squeeze(-1), labels.float())\n",
    "\n",
    "            #Backpropagating the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            #Optimization step\n",
    "            opti.step()\n",
    "              \n",
    "            if it % 100 == 0:\n",
    "                \n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "                st = time.time()\n",
    "\n",
    "        \n",
    "        dev_acc, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n",
    "        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n",
    "        if dev_acc > best_acc:\n",
    "            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "            best_acc = dev_acc\n",
    "            torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-sxGWQ439zS"
   },
   "source": [
    "Notice that we check the development performance after every training epoch, and only save the model when we see a performance improvement.\n",
    "\n",
    "A couple more housekeeping functions we need to define for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 37400,
     "status": "ok",
     "timestamp": 1618296984021,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "L2qR1DKQ39zS"
   },
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "def evaluate(net, criterion, dataloader, gpu):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks, labels in dataloader:\n",
    "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
    "            logits = net(seq, attn_masks)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYqaIiqUnE-U"
   },
   "source": [
    "We're almost ready to fine-tune the sentiment classifier! We'll train with 1 epoch and see what performance we get.\n",
    "\n",
    "There are about 1000 iterations for one epoch, and generally 100 iterations takes about 20-35 seconds (depending what GPU you're randomly allocated), so one epoch of training should hopefully take no more than 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407719,
     "status": "ok",
     "timestamp": 1618297354342,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "grPQtazw39zV",
    "outputId": "4e59ef78-c691-40cb-e45a-f9cfb4ef10d1"
   },
   "outputs": [],
   "source": [
    "num_epoch = 1\n",
    "\n",
    "#fine-tune the model\n",
    "train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fk0XYLP-k5I"
   },
   "source": [
    "Hopefully your model should get around 90% accuracy, which is a pretty good performance. Feel free to run again but with more epochs and see if you can get a better performance."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "10-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1c9ab2648f5a46e2a7d597b1864bfd73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aba1e75e26b4835b0c165c46b1185c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2c33295e9e194beea8288f61084965db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37a1805a791b43bc9ba1d73948637d65": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b4c267b7ad84748841b1d9a6af6d93b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4125d0410f38414e81dad276d1e882ad",
       "IPY_MODEL_fb57e22ba2ee44baae2bb834d56b93e8"
      ],
      "layout": "IPY_MODEL_fb34b640799c41d89788a07190d53c36"
     }
    },
    "4125d0410f38414e81dad276d1e882ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53a23b0c63874ad0a02533ef7a536600",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e9552fe12084124866f393272f0ff6a",
      "value": 28
     }
    },
    "498525097ea14544ac558920c387bf7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ad237b0e16c4243b7b0b2fb8a428cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51d92c91a2a24616b389d9aff1e021b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c33295e9e194beea8288f61084965db",
      "placeholder": "",
      "style": "IPY_MODEL_e8e0159d124c49d28770433457f526d1",
      "value": " 440M/440M [00:13&lt;00:00, 33.6MB/s]"
     }
    },
    "52651e00187e4df087181b6fc25e05c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a23b0c63874ad0a02533ef7a536600": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56b8940646da472983892ec6d3c6aa98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6681c34c26174cd8b2e814ed4e15f87b",
      "placeholder": "",
      "style": "IPY_MODEL_932670e9e28b48a28dfbceb141db7c19",
      "value": " 466k/466k [00:00&lt;00:00, 1.22MB/s]"
     }
    },
    "5d9636dd20f047a797ab17f6de8f9092": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c9ab2648f5a46e2a7d597b1864bfd73",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c47214219e3949448867964eb041ea0a",
      "value": 466062
     }
    },
    "6681c34c26174cd8b2e814ed4e15f87b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c4d3eaaae4048b4a049e04b52c9ce2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6c72db6eda8349d9854cce41c22751eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7322fae0d93e420c87b04b9fe76592fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b93a28e1141420dbda5776e4bb2ea25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_498525097ea14544ac558920c387bf7f",
      "placeholder": "",
      "style": "IPY_MODEL_7d5abd77586d4b6d91c4088f32d10ce9",
      "value": " 433/433 [00:13&lt;00:00, 32.0B/s]"
     }
    },
    "7d5abd77586d4b6d91c4088f32d10ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ddafd877934427ca608eb50d277c6cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "932670e9e28b48a28dfbceb141db7c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ab077c6d9f34e00aa2901e5903d7580": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37a1805a791b43bc9ba1d73948637d65",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2aba1e75e26b4835b0c165c46b1185c6",
      "value": 440473133
     }
    },
    "9e9552fe12084124866f393272f0ff6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9fc0faf7ddd0476c9f32d4cf8ef342f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ad237b0e16c4243b7b0b2fb8a428cbd",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e123376683094b41a8e151deb142792e",
      "value": 433
     }
    },
    "a558fc732c0c4c4b8a12605616d16ad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fc0faf7ddd0476c9f32d4cf8ef342f2",
       "IPY_MODEL_7b93a28e1141420dbda5776e4bb2ea25"
      ],
      "layout": "IPY_MODEL_cde329ab4a2f4e309625b83d983eb665"
     }
    },
    "b252d105ce094f67ad6018babf79e503": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d9636dd20f047a797ab17f6de8f9092",
       "IPY_MODEL_56b8940646da472983892ec6d3c6aa98"
      ],
      "layout": "IPY_MODEL_e3720bead30647298a5385313f3c1f13"
     }
    },
    "b50cb156207047cd8f441ea8470f9c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ddafd877934427ca608eb50d277c6cc",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c4d3eaaae4048b4a049e04b52c9ce2a",
      "value": 231508
     }
    },
    "b75137e6267f46668a8e96dbd40b97f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b50cb156207047cd8f441ea8470f9c21",
       "IPY_MODEL_d4732e5208b64242a6dd69ece05aff11"
      ],
      "layout": "IPY_MODEL_7322fae0d93e420c87b04b9fe76592fe"
     }
    },
    "b7536f77337c48b3ad5486076262d167": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ab077c6d9f34e00aa2901e5903d7580",
       "IPY_MODEL_51d92c91a2a24616b389d9aff1e021b2"
      ],
      "layout": "IPY_MODEL_52651e00187e4df087181b6fc25e05c1"
     }
    },
    "bd64e784923b40139c25b863d572a14b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c47214219e3949448867964eb041ea0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cde329ab4a2f4e309625b83d983eb665": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf92febcf4724c5fa98205d103dcf918": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4732e5208b64242a6dd69ece05aff11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2b65a56abce4c1bb4fa4839e128ccfc",
      "placeholder": "",
      "style": "IPY_MODEL_6c72db6eda8349d9854cce41c22751eb",
      "value": " 232k/232k [00:02&lt;00:00, 111kB/s]"
     }
    },
    "e123376683094b41a8e151deb142792e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e2b65a56abce4c1bb4fa4839e128ccfc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3720bead30647298a5385313f3c1f13": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8e0159d124c49d28770433457f526d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb34b640799c41d89788a07190d53c36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb57e22ba2ee44baae2bb834d56b93e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf92febcf4724c5fa98205d103dcf918",
      "placeholder": "",
      "style": "IPY_MODEL_bd64e784923b40139c25b863d572a14b",
      "value": " 28.0/28.0 [00:00&lt;00:00, 31.6B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
