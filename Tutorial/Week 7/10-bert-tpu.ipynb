{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wLWYdE939yj"
   },
   "source": [
    "# Fine-tuning with BERT\n",
    "\n",
    "In this workshop, we'll learn how to use a pre-trained BERT model for a sentiment analysis task. We'll be using the [pytorch](https://pytorch.org/) framework, and [huggingface's transformers library](https://github.com/huggingface/transformers), which provides a suite of transformer models with a consistent interface.\n",
    "\n",
    "Note: You may find certain parts of the code difficult to follow. This is because the model is designed based on the pytorch framework, so there'll be  pytorch syntax littered throughout the code. If you want to understand the code better, you're encouraged to do the [pytorch tutorial](https://pytorch.org/tutorials/), and also going through [the code of a pytorch language model](https://github.com/pytorch/examples/tree/master/word_language_model).\n",
    "\n",
    "Now let's enable TPU on the colab notebook. We can do this by going to \"Runtime $>$ Change runtime type\" and selecting \"TPU\" as the hardware accelerator. Click save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzCW5f2vnE9b"
   },
   "source": [
    "First let's install the pytorch and transformers packages and Pytorch-XLA for TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9835,
     "status": "ok",
     "timestamp": 1618297592979,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "zkioaw3DnE9c",
    "outputId": "c56b7a78-bc1e-4b2b-91a6-1f4d49ab171b"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20686,
     "status": "ok",
     "timestamp": 1618297626468,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "F6B8sa2Q-C5-",
    "outputId": "00095a91-c2f1-42c2-8536-7bfb3b8dbcc9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
    "\n",
    "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1618297699194,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "N1Erzh7t-C5-",
    "outputId": "df007e51-ca2a-45ac-8dc0-e51dc9f61abc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#[FOR TPU]\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.utils.utils as xu\n",
    "\n",
    "#[FOR TPU] Checking device\n",
    "t = torch.randn(2, 2, device=xm.xla_device())\n",
    "print(t.device)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0LPPNAInE9i"
   },
   "source": [
    "The installation will take a couple minutes.\n",
    "\n",
    "Once the packages are installed, we'll load a pre-trained BERT model. We'll use the smaller uncased BERT model (uncased means the data used for pre-training BERT is all lowercased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132,
     "referenced_widgets": [
      "8bb42d9dde434b728ae375b6d5200c84",
      "f935b20e897e4110b70bde0d4e3a06d9",
      "d4ed6e064c764d318d3e782e30606f2e",
      "796a6c855a8f45f0acb8c1265079fe5c",
      "da5acd045e374b4f8c7009b0529aa06d",
      "5182c42558704f6a970254fe6947009c",
      "8f56f54845a6414099cf28e765dbd161",
      "8a455b9a9c124584a1c57c6da460ef00",
      "bdb4d3e3a6d946ec905a20c03a0fb4bc",
      "f0b9d89e801643e8b7ba9937903b85c2",
      "dc4c5b7d6b324a8495d92cc58f1fd7d1",
      "43bab0df0621477fb691e2d7020f941d",
      "ebd02d96a8434a169f9d3ed992ac928d",
      "bf2d96d4f9054d66bcaf68ca5578a481",
      "5d6590db7f2b4c8e917fc92878f9cd1f",
      "75468abd0e854c0da035bca950cd99be"
     ]
    },
    "executionInfo": {
     "elapsed": 15519,
     "status": "ok",
     "timestamp": 1618297713401,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "sgde1MeD39yk",
    "outputId": "b5071133-edbb-4c22-c187-bcd497d6087b"
   },
   "outputs": [],
   "source": [
    "#load pretrained bert base model\n",
    "from transformers import BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"Done loading BERT model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59ifoyqGA-7m"
   },
   "source": [
    "BERT uses WordPiece tokenisation, which is a sub-word tokenisation algorithm like BPE. Let's tokenise a sentence with WordPiece and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181,
     "referenced_widgets": [
      "99b8bd2d48c54f65aa516e8b2de3c928",
      "81a46c81a58246f299a3e9c3e22cb5d5",
      "acf6038db5f44626bcd021ceeb752b1b",
      "5634c9a5577147d49abc9c59f3a0e995",
      "fe5348e18a344367882bdbfd1b49275a",
      "e81b3c74aabc42f0bdf9acfc3fffe5da",
      "73de279961f24075ad12761ba5e92d75",
      "838b13a08a654027a18157edd82018a2",
      "2ca14355fbe44e93ab76730a17902e8e",
      "a06a95d4307349f9a5914ddb712875c3",
      "985c8542e4f14fa59a56b314404aa55c",
      "7fd9a69569c440b3aac234976b845c15",
      "f7ec9a8aadf5461498700f0de32e6cc6",
      "c705d088d25a40ff881c650d487cca16",
      "0e60b752587e442e90ee68900f514c20",
      "fe0a77208a444807abe122cc3b0d2321",
      "3251e6873a03451d9b9341377761b00b",
      "de85bd2b4f1d4aa48a4506c617b2513c",
      "e9d730b18c4d453ab3a3b27e54abae28",
      "ecab354371fd4f44878334172a8d7705",
      "488ec410e071491b8372e2dc90820b34",
      "9dce995e88df4c77b34d7a442f1a936b",
      "59e191d1d3a14362beba0f864ae73136",
      "692463cf552a4949b37a3512cc995d32"
     ]
    },
    "executionInfo": {
     "elapsed": 16959,
     "status": "ok",
     "timestamp": 1618297714849,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "2EqbuS_f39yu",
    "outputId": "df8bcd92-c390-460a-d0a9-79a9c0bb327b"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#load BERT's WordPiece tokenisation model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentence = 'I enjoyed this movie sooooo much.'\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6IDDDbznE9p"
   },
   "source": [
    "We can see for most words, they are tokenised as single words. But for the word \"sooooo\" it's tokenised into three subwords: \"soo\", \"##oo\" and \"##o\". The double hashtag \"##\" is a symbol to indicate a subword span of within a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTrn2FVu39yw"
   },
   "source": [
    "BERT prepends every sentence with a special [CLS] token. As we saw in the lecture, we need this token when we fine-tune BERT for downstream tasks (e.g. spam detection).\n",
    "\n",
    "BERT also terminates a sentence with a special [SEP] token. While this token doesn't do much when we're working with problems that have single sentences as input (e.g. sentiment classification), it's useful when we're working with problems that involve sentence pairs (e.g. textual entailment and sentence similarity classification). In those cases, we need [SEP] to indicate when the first sentence finishes, and when the second sentence starts (e.g. for the sentence pair (_this movie is fantastic_, _this film is amazing_), the input to BERT will be: `[CLS] this movie is fantastic [SEP] this film is amazing [SEP]`).\n",
    "\n",
    "Note: Recall that in addition to the masked language model objective, BERT is also pre-trained with the next-sentence prediction objective. [SEP] is needed for the next-sentence objective (since it involves a sentence pair), and [CLS] is also used in this objective to classify the input sentence pair. And so [CLS] and [SEP] isn't used only during fine-tuning; they are also used during pre-training.\n",
    "\n",
    "Now let's preprocess the sentence by prepending [CLS] and appending [SEP]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16952,
     "status": "ok",
     "timestamp": 1618297714850,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "ZTAmBw3D39yx",
    "outputId": "b7bb7bdb-d809-4c06-e7db-42a51afc9b53"
   },
   "outputs": [],
   "source": [
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YMusTTk39y0"
   },
   "source": [
    "Since we'll be using minibatches when fine-tuning BERT, we need to pad the input sequences so that they are all of the same length. We'll use the [PAD] token for this.\n",
    "\n",
    "Additionally, we need to create an attention mask vector. This attention mask vector is a binary vector and it tells BERT what words should and should not be attended. We need the attention mask vector here because we want BERT to ignore the [PAD] tokens (i.e. to not consider them when doing self-attention).\n",
    "\n",
    "Now let's pad the input sequence to a fixed length (12 in this example) and create the binary attention mask vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16942,
     "status": "ok",
     "timestamp": 1618297714850,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "YzSB6zff39y0",
    "outputId": "fb97fb2d-a3c8-45c1-fb3a-4eac3d50b58b"
   },
   "outputs": [],
   "source": [
    "T = 12\n",
    "\n",
    "padded_tokens = tokens + ['[PAD]' for _ in range(T - len(tokens))]\n",
    "print(padded_tokens)\n",
    "\n",
    "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "print(attn_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xsoI8Hz39y3"
   },
   "source": [
    "The last preprocessing step is to create the segment IDs. The segment IDs is again a binary vector, and denotes the sentence IDs (first or second sentence) in the input sequence. We use 0 to denote the first sentence, and 1 the second sentence. As we are working with a single sentence as input for sentiment analysis, the segment IDs is just a vector of 0's. But for a sentence pair classification problem like sentence similarity classification, an input like `[CLS] this movie is fantastic [SEP] this film is amazing [SEP]` would have a segment IDs of `[0 0 0 0 0 0 1 1 1 1 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16935,
     "status": "ok",
     "timestamp": 1618297714851,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "pwdVZux_39y3",
    "outputId": "f7fafa09-d614-46ed-ac15-79cf79735448"
   },
   "outputs": [],
   "source": [
    "seg_ids = [0 for _ in range(len(padded_tokens))] #Since we only have a single sequence as input\n",
    "print(seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-d4Fdn039y7"
   },
   "source": [
    "Now let's convert the tokens in preprocessed sentence into their respective vocab IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16928,
     "status": "ok",
     "timestamp": 1618297714851,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "Gc79UDdt39y7",
    "outputId": "a66ba1b2-dd84-4691-c497-f0aefbacd4f3"
   },
   "outputs": [],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2gyfDLB39y-"
   },
   "source": [
    "We can see [CLS] has a vocab ID of 101, [SEP] 102 and [PAD] 0.\n",
    "\n",
    "Next let's turn the IDs into torch tensors, and feed the input sequence to BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17294,
     "status": "ok",
     "timestamp": 1618297715224,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "jrQWFNd139y-",
    "outputId": "38acb8ab-894e-4834-b750-0146e191776c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Converting all the input vectors to torch tensors\n",
    "token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "\n",
    "#Feed them to bert and get the contextualised embeddings\n",
    "outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t)\n",
    "hidden_reps = outputs.last_hidden_state\n",
    "print(hidden_reps.shape)\n",
    "print(hidden_reps[0, 0, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6v5VMTm39zB"
   },
   "source": [
    "`output[0]` is the contextualised embeddings for all tokens in the sentence (CLS is the first token).\n",
    "\n",
    "It has a dimension of [1, 12, 768] because we have one sentence in our minibatch, and that sentence has a length of 12 tokens, and each token has a contextualised embedding of 768 dimensions.\n",
    "\n",
    "`output[1]` is the pooling output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_NGjrIk39zB"
   },
   "source": [
    "Now that we understood how to preprocess sentences and get the contextualised embeddings from BERT, let's move to the actual classification problem: sentiment analysis.\n",
    "\n",
    "We'll be using the Stanford sentiment treebank data as our dataset. Let's upload the data (10-train.tsv and 10-dev.tsv) to colab. We can do this by clicking the folder icon on the left, and selecting \"Upload\" to upload the two files.\n",
    "\n",
    "Once the files are uploaded, you should see them appearing in the file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIbjzUAInE97"
   },
   "source": [
    "We'll now create `SSTDataset`, a dataset class to load the data, and provide a function `__getitem__` to fetch a sentence, preprocess it (following the steps we did earlier) and return the tokenised sentence, attention mask and ground truth label.\n",
    "\n",
    "Note: we do not need to create the segment IDs here since we're working with a task (sentiment analysys) that only has single sentences as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17288,
     "status": "ok",
     "timestamp": 1618297715225,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "DGtUWjhr39zC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class SSTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename, maxlen):\n",
    "\n",
    "        #Store the contents of the file in a pandas dataframe\n",
    "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
    "\n",
    "        #Initialize the BERT tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        sentence = self.df.loc[index, 'sentence']\n",
    "        label = self.df.loc[index, 'label']\n",
    "\n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrc6aHBW39zE"
   },
   "source": [
    "Now let's create the training and development data using the `SSTDataset` class and pytorch's `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18524,
     "status": "ok",
     "timestamp": 1618297716467,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "pzhUQHT439zF",
    "outputId": "101c74db-34b2-4dc1-8483-d7b1a88a0c51"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Creating instances of training and development set\n",
    "#maxlen sets the maximum length a sentence can have\n",
    "#any sentence longer than this length is truncated to the maxlen size\n",
    "train_set = SSTDataset(filename = '10-train.tsv', maxlen = 30)\n",
    "dev_set = SSTDataset(filename = '10-dev.tsv', maxlen = 30)\n",
    "\n",
    "#Creating intsances of training and development dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = 64, num_workers = 5)\n",
    "dev_loader = DataLoader(dev_set, batch_size = 64, num_workers = 5)\n",
    "\n",
    "print(\"Done preprocessing training and development data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2t1KRAE39zH"
   },
   "source": [
    "Recall how we use BERT for downstream task:\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/bert-classifier.png\" width=\"70%\">\n",
    "\n",
    "We feed the input sequence to BERT, and take the contextualised embedding of [CLS] produced by BERT, and pass it to a classifier, which can be a simple feedforward network. As our task is a binary classification problem (positive or negative sentiment label), we only need the output layer to produce a single scalar value to denote the probability of the positive class.\n",
    "\n",
    "Note: when we fine-tune our model we'll update all the parameters in the model (BERT's and the classification layer's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18517,
     "status": "ok",
     "timestamp": 1618297716467,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "-mC5rpX939zI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Classification layer\n",
    "        #input dimension is 768 because [CLS] embedding has a dimension of 768\n",
    "        #output dimension is 1 because we're working with a binary classification problem\n",
    "        self.cls_layer = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head \n",
    "        cls_rep = cont_reps[:,0]\n",
    "\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbapDA4HnE-F"
   },
   "source": [
    "Now let's create the sentiment classifier with pre-trained BERT's parameters. We'll put the model on GPU. This step might take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27140,
     "status": "ok",
     "timestamp": 1618297725091,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "uuT4iQWN39zK",
    "outputId": "05085467-4611-4bcc-8a2d-f3c0d2aac2be"
   },
   "outputs": [],
   "source": [
    "# [FOR GPU]\n",
    "#device = 0 #gpu ID\n",
    "#print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n",
    "#net = SentimentClassifier()\n",
    "#net.cuda(device) #Enable gpu support for the model\n",
    "#print(\"Done creating the sentiment classifier.\")\n",
    "\n",
    "\n",
    "# [FOR TPU]\n",
    "# Only instantiate model weights once in memory.\n",
    "print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n",
    "WRAPPED_MODEL = xmp.MpModelWrapper(SentimentClassifier())\n",
    "\n",
    "device = xm.xla_device() \n",
    "model = WRAPPED_MODEL.to(device) #Enable TPU support for the model\n",
    "print(\"Done creating the sentiment classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaKjG-RL39zN"
   },
   "source": [
    "We need to define a loss function for our model. Since it's a binary task, we'll use binary cross-entropy. We'll also use Adam as our optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27135,
     "status": "ok",
     "timestamp": 1618297725092,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "uEFvInHa39zN"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 2e-5\n",
    "# [FOR TPU] need to scale learning rate to world size.\n",
    "lr = lr * xm.xrt_world_size() # remove this if you want to run with GPU\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opti = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bczJ88nc39zP"
   },
   "source": [
    "Next let's define the training function. During training, we fetch a minibatch of examples from the data loader, and feed it to the classifier to get the output logits and compute the loss. `loss.backward()` is a function to compute the gradients for the parameters based on the loss, and `opti.step()` is a function to update parameters using the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27129,
     "status": "ok",
     "timestamp": 1618297725092,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "NZlOKYq339zP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, criterion, opti, train_loader, dev_loader, max_eps, device):\n",
    "\n",
    "    best_acc = 0\n",
    "    st = time.time()\n",
    "    for ep in range(max_eps):\n",
    "        \n",
    "        net.train()\n",
    "        # [FOR TPU] Using ParalellLoader\n",
    "        train_loader2 = pl.ParallelLoader(train_loader, [device])\n",
    "        train_loader2 = train_loader2.per_device_loader(device)\n",
    "        dev_loader2 = pl.ParallelLoader(dev_loader, [device])\n",
    "        dev_loader2 = dev_loader2.per_device_loader(device)\n",
    "        \n",
    "        for it, (seq, attn_masks, labels) in enumerate(train_loader2):\n",
    "            #Clear gradients\n",
    "            opti.zero_grad()  \n",
    "\n",
    "            #[FOR GPU] Converting these to cuda tensors\n",
    "            #seq, attn_masks, labels = seq.cuda(device), attn_masks.cuda(device), labels.cuda(device)\n",
    "\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, attn_masks)\n",
    "\n",
    "            #Computing loss\n",
    "            loss = criterion(logits.squeeze(-1), labels.float())\n",
    "\n",
    "            #Backpropagating the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            #[FOR GPU] Optimization step\n",
    "            #opti.step()\n",
    "\n",
    "            #[FOR TPU] Optimization step\n",
    "            xm.optimizer_step(opti)\n",
    "\n",
    "            if it % 100 == 0:\n",
    "                #Please remove [xla:{}] and xm.get_ordinal() if you want to run with GPU\n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                print(\"[xla:{}] Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(xm.get_ordinal(), it, ep, loss.item(), acc, (time.time()-st)))\n",
    "                st = time.time()\n",
    "     \n",
    "        dev_acc, dev_loss = evaluate(net, criterion, dev_loader2, device)\n",
    "        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n",
    "        if dev_acc > best_acc:\n",
    "            print(\"Best development accuracy improved from {} to {}, saving model...\".format( best_acc, dev_acc))\n",
    "            best_acc = dev_acc\n",
    "            torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-sxGWQ439zS"
   },
   "source": [
    "Notice that we check the development performance after every training epoch, and only save the model when we see a performance improvement.\n",
    "\n",
    "A couple more housekeeping functions we need to define for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27125,
     "status": "ok",
     "timestamp": 1618297725093,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "L2qR1DKQ39zS"
   },
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    #[FOR TPU] Using ParalellLoader\n",
    "    dataloader = pl.ParallelLoader(dataloader, [device])\n",
    "    dataloader = dataloader.per_device_loader(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks, labels in dataloader:\n",
    "            #[FOR GPU] Converting these to cuda tensors\n",
    "            #seq, attn_masks, labels = seq.cuda(device), attn_masks.cuda(device), labels.cuda(device)\n",
    "            logits = net(seq, attn_masks)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYqaIiqUnE-U"
   },
   "source": [
    "We're almost ready to fine-tune the sentiment classifier! We'll train with 1 epoch and see what performance we get.\n",
    "\n",
    "There are about 1000 iterations for one epoch, and generally 100 iterations takes about 15 seconds on TPU or 20-35 seconds on GPU, so TPU is quite a bit faster than TPU. Note, though, that you might find TPU slower in the first 300 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333793,
     "status": "ok",
     "timestamp": 1618298031767,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "grPQtazw39zV",
    "outputId": "6a516eeb-c32a-4778-df0e-742714870d1b"
   },
   "outputs": [],
   "source": [
    "num_epoch = 1\n",
    "\n",
    "#fine-tune the model\n",
    "train(model, criterion, opti, train_loader, dev_loader, num_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fk0XYLP-k5I"
   },
   "source": [
    "Hopefully your model should get around 90% accuracy, which is a pretty good performance. Feel free to run again but with more epochs and see if you can get a better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 333793,
     "status": "ok",
     "timestamp": 1618298031768,
     "user": {
      "displayName": "Jey Han Lau",
      "photoUrl": "",
      "userId": "09065329932778503205"
     },
     "user_tz": -600
    },
    "id": "vErDu9Ii39zY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "10-bert-TPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e60b752587e442e90ee68900f514c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ca14355fbe44e93ab76730a17902e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_985c8542e4f14fa59a56b314404aa55c",
       "IPY_MODEL_7fd9a69569c440b3aac234976b845c15"
      ],
      "layout": "IPY_MODEL_a06a95d4307349f9a5914ddb712875c3"
     }
    },
    "3251e6873a03451d9b9341377761b00b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9d730b18c4d453ab3a3b27e54abae28",
       "IPY_MODEL_ecab354371fd4f44878334172a8d7705"
      ],
      "layout": "IPY_MODEL_de85bd2b4f1d4aa48a4506c617b2513c"
     }
    },
    "43bab0df0621477fb691e2d7020f941d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75468abd0e854c0da035bca950cd99be",
      "placeholder": "​",
      "style": "IPY_MODEL_5d6590db7f2b4c8e917fc92878f9cd1f",
      "value": " 440M/440M [00:10&lt;00:00, 43.0MB/s]"
     }
    },
    "488ec410e071491b8372e2dc90820b34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5182c42558704f6a970254fe6947009c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5634c9a5577147d49abc9c59f3a0e995": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_838b13a08a654027a18157edd82018a2",
      "placeholder": "​",
      "style": "IPY_MODEL_73de279961f24075ad12761ba5e92d75",
      "value": " 232k/232k [00:00&lt;00:00, 362kB/s]"
     }
    },
    "59e191d1d3a14362beba0f864ae73136": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d6590db7f2b4c8e917fc92878f9cd1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "692463cf552a4949b37a3512cc995d32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73de279961f24075ad12761ba5e92d75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75468abd0e854c0da035bca950cd99be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "796a6c855a8f45f0acb8c1265079fe5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a455b9a9c124584a1c57c6da460ef00",
      "placeholder": "​",
      "style": "IPY_MODEL_8f56f54845a6414099cf28e765dbd161",
      "value": " 433/433 [00:14&lt;00:00, 29.3B/s]"
     }
    },
    "7fd9a69569c440b3aac234976b845c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe0a77208a444807abe122cc3b0d2321",
      "placeholder": "​",
      "style": "IPY_MODEL_0e60b752587e442e90ee68900f514c20",
      "value": " 28.0/28.0 [00:00&lt;00:00, 52.8B/s]"
     }
    },
    "81a46c81a58246f299a3e9c3e22cb5d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "838b13a08a654027a18157edd82018a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a455b9a9c124584a1c57c6da460ef00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bb42d9dde434b728ae375b6d5200c84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4ed6e064c764d318d3e782e30606f2e",
       "IPY_MODEL_796a6c855a8f45f0acb8c1265079fe5c"
      ],
      "layout": "IPY_MODEL_f935b20e897e4110b70bde0d4e3a06d9"
     }
    },
    "8f56f54845a6414099cf28e765dbd161": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "985c8542e4f14fa59a56b314404aa55c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c705d088d25a40ff881c650d487cca16",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7ec9a8aadf5461498700f0de32e6cc6",
      "value": 28
     }
    },
    "99b8bd2d48c54f65aa516e8b2de3c928": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acf6038db5f44626bcd021ceeb752b1b",
       "IPY_MODEL_5634c9a5577147d49abc9c59f3a0e995"
      ],
      "layout": "IPY_MODEL_81a46c81a58246f299a3e9c3e22cb5d5"
     }
    },
    "9dce995e88df4c77b34d7a442f1a936b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a06a95d4307349f9a5914ddb712875c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acf6038db5f44626bcd021ceeb752b1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e81b3c74aabc42f0bdf9acfc3fffe5da",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe5348e18a344367882bdbfd1b49275a",
      "value": 231508
     }
    },
    "bdb4d3e3a6d946ec905a20c03a0fb4bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc4c5b7d6b324a8495d92cc58f1fd7d1",
       "IPY_MODEL_43bab0df0621477fb691e2d7020f941d"
      ],
      "layout": "IPY_MODEL_f0b9d89e801643e8b7ba9937903b85c2"
     }
    },
    "bf2d96d4f9054d66bcaf68ca5578a481": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c705d088d25a40ff881c650d487cca16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ed6e064c764d318d3e782e30606f2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5182c42558704f6a970254fe6947009c",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da5acd045e374b4f8c7009b0529aa06d",
      "value": 433
     }
    },
    "da5acd045e374b4f8c7009b0529aa06d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dc4c5b7d6b324a8495d92cc58f1fd7d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf2d96d4f9054d66bcaf68ca5578a481",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ebd02d96a8434a169f9d3ed992ac928d",
      "value": 440473133
     }
    },
    "de85bd2b4f1d4aa48a4506c617b2513c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e81b3c74aabc42f0bdf9acfc3fffe5da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9d730b18c4d453ab3a3b27e54abae28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dce995e88df4c77b34d7a442f1a936b",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_488ec410e071491b8372e2dc90820b34",
      "value": 466062
     }
    },
    "ebd02d96a8434a169f9d3ed992ac928d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ecab354371fd4f44878334172a8d7705": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_692463cf552a4949b37a3512cc995d32",
      "placeholder": "​",
      "style": "IPY_MODEL_59e191d1d3a14362beba0f864ae73136",
      "value": " 466k/466k [00:00&lt;00:00, 2.05MB/s]"
     }
    },
    "f0b9d89e801643e8b7ba9937903b85c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7ec9a8aadf5461498700f0de32e6cc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f935b20e897e4110b70bde0d4e3a06d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe0a77208a444807abe122cc3b0d2321": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe5348e18a344367882bdbfd1b49275a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
